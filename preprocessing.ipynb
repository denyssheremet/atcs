{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be3e2bab-46c3-4596-b02f-1d591772bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq datasets torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11e252c-0a67-499a-b288-b65f2a2d27d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71699475f67c487aa8dda1ce5de689d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7026b0c42af244558c9950d423534cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/412k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f185d0be0334fa9a54f698d3158f3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/413k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7d59c64f254544b119e239c03ddaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/19.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a2efe1ea054451b5a3a8bb806e90af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cba27286ec744b2aa2e5d19dc7e80a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b65e0094d84a979a9ec41274304c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/550152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['premise', 'hypothesis', 'label'],\n",
       "     num_rows: 550152\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['premise', 'hypothesis', 'label'],\n",
       "     num_rows: 10000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['premise', 'hypothesis', 'label'],\n",
       "     num_rows: 10000\n",
       " }))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset, get_dataset_split_names\n",
    "ds_train, ds_val, ds_test = load_dataset(\"stanfordnlp/snli\", split=['train', 'validation', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c911ea5-55ff-44fb-9381-d8eccf5979b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchtext.vocab import GloVe, build_vocab_from_iterator\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b65a76b-203f-450d-af74-eb237352a1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc5d6c262604b6794f46b33de3447c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/550152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85f60ac676240539ac1e35014d79613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d6f959647e43d6ba6ef6e3fc364d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_item(item):\n",
    "    item['premise'] = word_tokenize(item['premise'].lower())\n",
    "    item['hypothesis'] = word_tokenize(item['hypothesis'].lower())\n",
    "    return item\n",
    "\n",
    "# # load the datasets or if not available, preprocess them again. \n",
    "# import pickle\n",
    "# try: \n",
    "#     with open('all_ds_tok.pickle', 'rb') as handle:\n",
    "#         all_ds_tok = pickle.load(handle)\n",
    "    \n",
    "#     ds_train_tok = all_ds_tok[0]\n",
    "#     ds_val_tok   = all_ds_tok[1]\n",
    "#     ds_test_tok  = all_ds_tok[2]\n",
    "# except: \n",
    "ds_train_tok = ds_train.map(preprocess_item)\n",
    "ds_val_tok = ds_val.map(preprocess_item)\n",
    "ds_test_tok = ds_test.map(preprocess_item)\n",
    "all_ds_tok = [ds_train_tok, ds_val_tok, ds_test_tok]\n",
    "\n",
    "# with open('all_ds_tok.pickle', 'wb') as handle:\n",
    "#     pickle.dump(all_ds_tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d63066-6036-4ba1-854c-41ab3dab6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all the unique tokens\n",
    "def get_all_unique_toks(all_ds_tok):\n",
    "    all_unique_toks = set()\n",
    "    for ds in all_ds_tok:\n",
    "        for item in tqdm.tqdm(ds):\n",
    "            for key in ['premise', 'hypothesis']:\n",
    "                for tok in item[key]:\n",
    "                    if not tok in all_unique_toks:\n",
    "                        all_unique_toks.add(tok)\n",
    "    return all_unique_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f789ec-a3fa-46c8-8dc4-556b473b95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "try: \n",
    "    with open('all_unique_toks.pickle', 'rb') as handle:\n",
    "        all_unique_toks = pickle.load(handle)\n",
    "except: \n",
    "    all_unique_toks = get_all_unique_toks(all_ds_tok)\n",
    "    with open('all_unique_toks.pickle', 'wb') as handle:\n",
    "        pickle.dump(all_unique_toks, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "756abbfa-1a42-41e8-8e54-d45b4057311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = GloVe(name='840B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85d89eb9-36f8-4710-97f3-ef95d9010cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vocab = build_vocab_from_iterator(\n",
    "    [iter(all_unique_toks)],\n",
    "    specials=['<unk>'],\n",
    "    special_first=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd8decea-dfc6-40d5-93b3-6005ac57b587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37210, 37211)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_unique_toks), len(glove_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e29202d9-fe39-43de-8b5a-ba409d1ea2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_index(item):\n",
    "    item['premise'] = glove_vocab.lookup_indices(item['premise'])    \n",
    "    item['hypothesis'] = glove_vocab.lookup_indices(item['hypothesis'])\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2de97277-d106-4505-b1c1-3b75334352ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa2caf52c6f477db6fc0813308ee5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/550152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573561ce7e654b569ea4831bb380b7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/550152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022979459d2a42ba9685ccdae78cc26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b9f0c8a1e04e489bf118c63a56d223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3403daa2e1ca434da73063a5eb07d1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b81ac75d524cb6bcadb7ef19901712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the datasets or if not available, convert to indices again. \n",
    "import pickle\n",
    "try: \n",
    "    with open('all_ds_prep.pickle', 'rb') as handle:\n",
    "        all_ds_prep = pickle.load(handle)\n",
    "    ds_train_prep = all_ds_prep[0]\n",
    "    ds_val_prep = all_ds_prep[1]\n",
    "    ds_test_prep = all_ds_prep[2]\n",
    "except: \n",
    "    # map to index and remove items with label -1\n",
    "    ds_train_prep = ds_train_tok.map(token_to_index).filter(lambda x: x['label'] >= 0)\n",
    "    ds_val_prep   = ds_val_tok.map(token_to_index).filter(lambda x: x['label'] >= 0)\n",
    "    ds_test_prep  = ds_test_tok.map(token_to_index).filter(lambda x: x['label'] >= 0)\n",
    "    all_ds_prep = [ds_train_prep, ds_val_prep, ds_test_prep]\n",
    "    \n",
    "    with open('all_ds_prep.pickle', 'wb') as handle:\n",
    "        pickle.dump(all_ds_prep, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5efa76a3-ea09-4c58-afa8-701c31eba9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find longest sentence\n",
    "# max_sent_len = -1\n",
    "# for ds in all_ds_prep:\n",
    "#     for item in ds:\n",
    "#         max_sent_len = max(\n",
    "#             max_sent_len,\n",
    "#             len(item['premise']),\n",
    "#             len(item['hypothesis'])\n",
    "#         )\n",
    "# print(max_sent_len)\n",
    "\n",
    "# max sentence length = 82\n",
    "max_sent_len = 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bad6b494-7aca-4ddb-9028-c5fe4b9e063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    # first find the longest sentences in the batch\n",
    "    max_p, max_h = -1, -1\n",
    "    for d in data:\n",
    "        max_p = max(max_p, len(d['premise']))\n",
    "        max_h = max(max_h, len(d['hypothesis']))\n",
    "    \n",
    "    # pad all sentences to same length\n",
    "    bs = len(data)\n",
    "    batch_p = torch.zeros((bs,max_p), dtype=torch.int32)\n",
    "    batch_h = torch.zeros((bs,max_h), dtype=torch.int32)\n",
    "    batch_l = torch.zeros((bs), dtype=torch.int64)\n",
    "    \n",
    "    for i, d in enumerate(data):\n",
    "        batch_p[i, 0:len(d['premise'])] = torch.tensor(d['premise'])\n",
    "        batch_h[i, 0:len(d['hypothesis'])] = torch.tensor(d['hypothesis'])\n",
    "        batch_l[i] = d['label']\n",
    "        \n",
    "    return batch_p, batch_h, batch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2b5691e-3018-44e5-91b1-597048773fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "bs = 64\n",
    "\n",
    "train_loader = DataLoader(ds_train_prep, collate_fn=collate_fn, batch_size=bs, shuffle=True)\n",
    "val_loader   = DataLoader(ds_val_prep, collate_fn=collate_fn, batch_size=bs, shuffle=True)\n",
    "test_loader  = DataLoader(ds_test_prep, collate_fn=collate_fn, batch_size=bs, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e4a9de4-525e-498d-b462-5d535b88f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # create the embedding layer and freeze the weights\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(\n",
    "            glove_vectors.get_vecs_by_tokens([\"<unk>\", *list(all_unique_toks)]),\n",
    "            freeze=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # unpack\n",
    "        premises, hypotheses, labels = x\n",
    "        # embed both the premise and hypothesis separately\n",
    "        premises = self.embedding_layer(premises)\n",
    "        hypotheses = self.embedding_layer(hypotheses)\n",
    "        return (premises, hypotheses, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "def3fcaa-92d8-48ce-aee1-7221e503f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    # the baseline encoder takes the average across word embeddings in a sentence\n",
    "    def forward(self, x):\n",
    "        # unpack\n",
    "        premises, hypotheses, labels = x\n",
    "        premises = premises.mean(axis=1)\n",
    "        hypotheses = hypotheses.mean(axis=1)\n",
    "        return (premises, hypotheses, labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05a3b21b-d511-4b64-9c17-f3044de90436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinationModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    # takes u and v (premise and hypothesis) \n",
    "    # and returns (u,v | u-v | u*v)\n",
    "    def forward(self, x):\n",
    "        # unpack\n",
    "        u, v, labels = x\n",
    "        out = torch.hstack([u,v,u-v,u*v])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ff48038-4291-47cc-afdb-a6c95a83c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3420fe4a-c681-479d-94bf-e946b1bd2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self, encoder, mlp):\n",
    "        super().__init__()\n",
    "        self.embedding_module = EmbeddingModule()\n",
    "        self.encoder = encoder\n",
    "        self.combination_module = CombinationModule()\n",
    "        self.mlp = mlp\n",
    "        self.model = nn.Sequential(\n",
    "            self.embedding_module,\n",
    "            self.encoder,\n",
    "            self.combination_module,\n",
    "            self.mlp\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def p(self):\n",
    "        print(self.model[1:])\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        torch.save(self.model[1:], filename)\n",
    "    \n",
    "    def load_model(self, filename):\n",
    "        layers = torch.load(filename)\n",
    "        for i, l in enumerate(layers):\n",
    "            self.model[i+1] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814932ec-eeab-40b1-bb0f-8786930fbe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullModel(\n",
       "  (embedding_module): EmbeddingModule(\n",
       "    (embedding_layer): Embedding(37211, 300)\n",
       "  )\n",
       "  (combination_module): CombinationModule()\n",
       "  (model): Sequential(\n",
       "    (0): EmbeddingModule(\n",
       "      (embedding_layer): Embedding(37211, 300)\n",
       "    )\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): ReLU()\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm = fm\n",
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "affe5b1b-14df-4599-b36a-f43f672ba635",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(nn.ReLU(), nn.ReLU(), nn.ReLU())\n",
    "torch.save(m, \"t.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43078bdd-824a-409c-92fe-04c62e098efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = nn.Sequential(\n",
    "    EmbeddingModule(),\n",
    "    BaselineEncoder(),\n",
    "    CombinationModule(),\n",
    "    MLP(in_dim=1200),\n",
    ").cuda()\n",
    "\n",
    "loss_module = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(baseline_model.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ced8a-6c9e-4a7c-a092-524e7468f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(baseline_model[1:], \"test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed60a2-58df-40b6-b248-0ad8481c689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load('test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f5738-9df3-4f53-a6df-670994539a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (1): BaselineEncoder()\n",
       "  (2): CombinationModule()\n",
       "  (3): MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=1200, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "      (3): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd7f87-375f-46f4-8bf1-091df0761db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    losses, accs = [], []\n",
    "    \n",
    "    for premises, hypotheses, targets in tqdm(loader):\n",
    "\n",
    "        hypotheses = hypotheses.cuda()\n",
    "        targets = targets.cuda()\n",
    "        premises = premises.cuda()\n",
    "            \n",
    "        predictions = baseline_model((premises, hypotheses, labels))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_module(predictions, targets)\n",
    "        acc = (predictions.argmax(axis=-1) == targets).float().mean()\n",
    "        \n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss = torch.tensor(losses).mean()\n",
    "    train_acc = torch.tensor(accs).mean()\n",
    "    return train_loss, train_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf9e98-de0e-4121-b891-2c7f2a7c1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure accuracy\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_correct = 0.\n",
    "    total = 0.\n",
    "    bs = loader.batch_size\n",
    "    \n",
    "    \n",
    "    for premises, hypotheses, targets in loader:\n",
    "        premises = premises.cuda()\n",
    "        hypotheses = hypotheses.cuda()\n",
    "        targets = targets.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = baseline_model((premises, hypotheses, labels)).argmax(axis=-1)\n",
    "        total_correct += (predictions==targets).float().sum()\n",
    "        total += bs\n",
    "        \n",
    "    acc = total_correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a85d8c8f-9f03-4782-bd32-a61c64e462d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr(optimizer, new_lr):\n",
    "    # update the learning rate for the optimizer\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = new_lr\n",
    "\n",
    "def train_loop(model, optimizer, train_loader, val_loader):\n",
    "    lr = 0.1\n",
    "    last_acc = -1\n",
    "    epoch = -1\n",
    "    \n",
    "    while lr > 1e-5:\n",
    "        epoch += 1\n",
    "        print(f'lr: {lr}')\n",
    "        #train and evaluate\n",
    "        train_loss, train_acc = train_epoch(model, train_loader)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Acc/train\", train_acc, epoch)\n",
    "\n",
    "        acc = evaluate(model, val_loader)\n",
    "        \n",
    "        writer.add_scalar(\"Acc/eval\", acc, epoch)\n",
    "        \n",
    "        print(f'acc: {acc}')\n",
    "        \n",
    "        \n",
    "        # learning rate decay\n",
    "        lr = lr * 0.99\n",
    "        update_lr(optimizer, lr)\n",
    "        \n",
    "        # if val acc goes down, divide lr by 5\n",
    "        if acc < last_acc:\n",
    "            lr = lr / 5.\n",
    "            update_lr(optimizer, lr)\n",
    "            \n",
    "        last_acc = acc\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d0c7b91c-d443-477c-b739-aba59a4b8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(baseline_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5a86cb20-0f6c-45af-9ccc-c343ba086bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8584/8584 [00:38<00:00, 220.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.3347199559211731\n",
      "lr: 0.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 6949/8584 [00:31<00:07, 220.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [153], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m      3\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn [151], line 15\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#train and evaluate\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_loss, epoch)\n\u001b[1;32m     17\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcc/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_acc, epoch)\n",
      "Cell \u001b[0;32mIn [122], line 7\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m losses, accs \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m premises, hypotheses, targets \u001b[38;5;129;01min\u001b[39;00m tqdm(loader):\n\u001b[1;32m      9\u001b[0m     premises \u001b[38;5;241m=\u001b[39m premises\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     10\u001b[0m     hypotheses \u001b[38;5;241m=\u001b[39m hypotheses\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [25], line 15\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_l \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((bs), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[0;32m---> 15\u001b[0m     batch_p[i, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mlen\u001b[39m(d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpremise\u001b[39m\u001b[38;5;124m'\u001b[39m])] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpremise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     batch_h[i, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mlen\u001b[39m(d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhypothesis\u001b[39m\u001b[38;5;124m'\u001b[39m])] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhypothesis\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     17\u001b[0m     batch_l[i] \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "train_loop(baseline_model, optimizer, train_loader, val_loader)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf796d-9469-460f-88d1-b9be36d3bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MLP to file\n",
    "torch.save(baseline_model[3], \"baseline_model_MLP.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b37601-5430-47c2-88f5-d2c45c68b139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3330, device='cuda:0')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(baseline_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e341413-a8bd-473e-b664-0438eb291bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mlp = torch.load(\"baseline_model_MLP.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04322ea-a900-43df-a801-c809091dd4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96da1a-5ef1-413b-bb80-f3f167e13b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
